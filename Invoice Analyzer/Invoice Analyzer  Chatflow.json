{
  "nodes": [
    {
      "id": "llmChain_0",
      "position": {
        "x": 581.389448718394,
        "y": 171
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_0",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_0-input-chainName-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_0-input-model-BaseLanguageModel",
            "display": true
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_0-input-prompt-BasePromptTemplate",
            "display": true
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_0-input-outputParser-BaseLLMOutputParser",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatDeepseek_0.data.instance}}",
          "prompt": "{{promptTemplate_0.data.instance}}",
          "outputParser": "{{structuredOutputParser_0.data.instance}}",
          "inputModeration": "",
          "chainName": "Invoice Analyzer "
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_0-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 513,
      "selected": false,
      "positionAbsolute": {
        "x": 581.389448718394,
        "y": 171
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_0",
      "position": {
        "x": 194.29548167654218,
        "y": 175.1514841871121
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_0",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_0-input-template-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_0-input-promptValues-json",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Extract the following information from the provided invoice:\n\n- Date\n- Ship Mode\n- Balance Due\n- Bill To\n- Item\n- Quantity \n- Rate \n- Amount\n- Subtotal\n- Discount\n- Shipping\n- Total\n\nif not exist write \"None\"\n\nINVOICE CONTENT:\n{invoice_pdf}",
          "promptValues": "{\"invoice_pdf\":\"{{file_attachment}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 517,
      "selected": false,
      "positionAbsolute": {
        "x": 194.29548167654218,
        "y": 175.1514841871121
      },
      "dragging": false
    },
    {
      "id": "chatDeepseek_0",
      "position": {
        "x": -187.83769222116604,
        "y": 126.36224893753365
      },
      "type": "customNode",
      "data": {
        "id": "chatDeepseek_0",
        "label": "ChatDeepseek",
        "version": 1,
        "name": "chatDeepseek",
        "type": "chatDeepseek",
        "baseClasses": [
          "chatDeepseek",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Deepseek large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "deepseekApi"
            ],
            "id": "chatDeepseek_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "deepseek-chat",
            "id": "chatDeepseek_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "chatDeepseek_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatDeepseek_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "Base Options",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "description": "Additional options to pass to the Deepseek client. This should be a JSON object.",
            "id": "chatDeepseek_0-input-baseOptions-json",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatDeepseek_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "deepseek-chat",
          "temperature": "0.3",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "stopSequence": "",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "chatDeepseek_0-output-chatDeepseek-chatDeepseek|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatDeepseek",
            "label": "chatDeepseek",
            "description": "Wrapper around Deepseek large language models that use the Chat endpoint",
            "type": "chatDeepseek | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 578,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -187.83769222116604,
        "y": 126.36224893753365
      }
    },
    {
      "id": "structuredOutputParser_0",
      "position": {
        "x": 960.9678245784055,
        "y": 270.1056058844267
      },
      "type": "customNode",
      "data": {
        "id": "structuredOutputParser_0",
        "label": "Structured Output Parser",
        "version": 1,
        "name": "structuredOutputParser",
        "type": "StructuredOutputParser",
        "baseClasses": [
          "StructuredOutputParser",
          "BaseLLMOutputParser",
          "Runnable"
        ],
        "category": "Output Parsers",
        "description": "Parse the output of an LLM call into a given (JSON) structure.",
        "inputParams": [
          {
            "label": "Autofix",
            "name": "autofixParser",
            "type": "boolean",
            "optional": true,
            "description": "In the event that the first call fails, will make another call to the model to fix any errors.",
            "id": "structuredOutputParser_0-input-autofixParser-boolean",
            "display": true
          },
          {
            "label": "JSON Structure",
            "name": "jsonStructure",
            "type": "datagrid",
            "description": "JSON structure for LLM to return",
            "datagrid": [
              {
                "field": "property",
                "headerName": "Property",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "string",
                  "number",
                  "boolean"
                ],
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "editable": true,
                "flex": 1
              }
            ],
            "default": [
              {
                "property": "answer",
                "type": "string",
                "description": "answer to the user's question"
              },
              {
                "property": "source",
                "type": "string",
                "description": "sources used to answer the question, should be websites"
              }
            ],
            "additionalParams": true,
            "id": "structuredOutputParser_0-input-jsonStructure-datagrid",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "autofixParser": true,
          "jsonStructure": "[{\"property\":\"Date\",\"type\":\"string\",\"description\":\"the date of the invoice\",\"actions\":\"\",\"id\":0},{\"property\":\"Ship_Mode\",\"type\":\"string\",\"description\":\"the mode of the item shipping\",\"actions\":\"\",\"id\":1},{\"property\":\"Balance_Due\",\"type\":\"string\",\"description\":\"the balance in the invoice\",\"actions\":\"\",\"id\":2},{\"property\":\"Bill_to\",\"type\":\"string\",\"description\":\"the name of the receiver \",\"actions\":\"\",\"id\":3},{\"property\":\"Item\",\"type\":\"string\",\"description\":\"the name of the item\",\"actions\":\"\",\"id\":4},{\"property\":\"Quantity\",\"type\":\"number\",\"description\":\"the Quantity of the ordered items \",\"actions\":\"\",\"id\":5},{\"property\":\"Rate\",\"type\":\"string\",\"description\":\"the price of a single product\",\"actions\":\"\",\"id\":6},{\"property\":\"Amount\",\"type\":\"string\",\"description\":\"the product of the number of product and the Rate\",\"actions\":\"\",\"id\":7},{\"property\":\"Subtotal\",\"type\":\"string\",\"description\":\"the Subtotal in the invoice\",\"actions\":\"\",\"id\":8},{\"property\":\"Discount\",\"type\":\"string\",\"description\":\"the Discount on the total cost\",\"actions\":\"\",\"id\":9},{\"property\":\"Shipping\",\"type\":\"string\",\"description\":\"the cost of the Shipping of the products\",\"actions\":\"\",\"id\":10},{\"property\":\"Total\",\"type\":\"string\",\"description\":\"the Total cost after shipping and discount \",\"actions\":\"\",\"id\":11}]"
        },
        "outputAnchors": [
          {
            "id": "structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable",
            "name": "structuredOutputParser",
            "label": "StructuredOutputParser",
            "description": "Parse the output of an LLM call into a given (JSON) structure.",
            "type": "StructuredOutputParser | BaseLLMOutputParser | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 334,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 960.9678245784055,
        "y": 270.1056058844267
      }
    }
  ],
  "edges": [
    {
      "source": "promptTemplate_0",
      "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
    },
    {
      "source": "chatDeepseek_0",
      "sourceHandle": "chatDeepseek_0-output-chatDeepseek-chatDeepseek|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatDeepseek_0-chatDeepseek_0-output-chatDeepseek-chatDeepseek|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "structuredOutputParser_0",
      "sourceHandle": "structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-outputParser-BaseLLMOutputParser",
      "type": "buttonedge",
      "id": "structuredOutputParser_0-structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable-llmChain_0-llmChain_0-input-outputParser-BaseLLMOutputParser"
    }
  ]
}